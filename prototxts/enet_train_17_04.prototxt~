name: "enet"
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  dense_image_data_param {
    source: "/home/timo/edssnas/IVR/Saemann/Cityscapes/train_fine_2columns_changed_labels.txt"	# Change this to the absolute path to your data file
    batch_size: 1   			# Change this number to a batch size that will fit on your GPU
    shuffle: true
    #new_height: 512
    #new_width: 1024
  }
########## initial block start
}
layer {
  name: "conv0_1"
  bottom: "data"
  top: "conv0_1"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    num_output: 13
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "pool0_1"
  type: "Pooling"
  bottom: "data"
  top: "pool0_1"
  top: "pool0_1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "concat0_1"
  type: "Concat"
  bottom: "conv0_1"
  bottom: "pool0_1"
  top: "concat0_1"
  concat_param {
    axis: 1
  }
}
########## initial block end
########## bottleneck stage 1 start
layer {
  name: "conv1_1"
  bottom: "concat0_1"
  top: "conv1_1"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    pad: 1
    num_output: 64
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "bn1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "prelu1_1"
  type: "PReLU"
  bottom: "bn1_1"
  top: "prelu1_1"
}
layer {
  name: "conv1_2"
  bottom: "prelu1_1"
  top: "conv1_2"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    #pad: 1
    num_output: 64
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "bn1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "prelu1_2"
  type: "PReLU"
  bottom: "bn1_2"
  top: "prelu1_2"
}


layer {
  name: "conv1_3"
  bottom: "prelu1_2"
  top: "conv1_3"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    num_output: 64
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn1_3"
  type: "BatchNorm"
  bottom: "conv1_3"
  top: "bn1_3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "prelu1_3"
  type: "PReLU"
  bottom: "bn1_3"
  top: "prelu1_3"
}
layer {
  name: "drop1_1"
  type: "Dropout"
  bottom: "prelu1_3"
  top: "drop1_1"
  dropout_param {
    dropout_ratio: 0.01
  }
}

layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "concat0_1"
  top: "pool1_1"
  top: "pool1_1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "concat1_1"
  type: "Concat"
  bottom: "pool1_1"
  bottom: "drop1_1"
  top: "concat1_1"
  concat_param {
    axis: 1
  }
}














layer {
  bottom: "concat1_1"
  top: "conv0_2"
  name: "conv0_2"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    num_output: 3
    pad: 1
    kernel_size: 3
  }
}
layer {
  bottom: "pool1_1_mask"
  top: "convX"
  name: "convX"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    num_output: 3
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "upsample0"
  type: "Upsample"
  bottom: "conv0_2"
  top: "upsample0"
  bottom: "convX"
  upsample_param {
    scale: 2
    #upsample_w: 120
    #upsample_h: 90
  }
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "upsample0"
  top: "upsample0"
  bottom: "pool0_1_mask"
  upsample_param {
    scale: 2
    #upsample_w: 480
    #upsample_h: 360
  }
}



layer {
  bottom: "upsample0"
  top: "convX2"
  name: "convX2"
  type: "Convolution"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    num_output: 12
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "convX2"
  bottom: "label"
  top: "loss"
  softmax_param {engine: CAFFE}
  loss_param: {
    #weight_by_label_freqs: false
    ignore_label: 254
    #normalize: true
   # class_weighting: 0.2595
   # class_weighting: 0.1826
   # class_weighting: 4.5640
   # class_weighting: 0.1417
   # class_weighting: 0.9051
   # class_weighting: 0.3826
   # class_weighting: 9.6446
    #class_weighting: 1.8418
    #class_weighting: 0.6823
    #class_weighting: 6.2478
    #class_weighting: 7.3614
    #class_weighting: 0.9051
    #class_weighting: 0.3826
    #class_weighting: 9.6446
    #class_weighting: 1.8418
    #class_weighting: 0.6823
    #class_weighting: 6.2478
    #class_weighting: 7.3614
    #class_weighting: 7.3614
  }
}
#layer {
#  name: "accuracy"
#  type: "Accuracy"
#  bottom: "convX2"
#  bottom: "label"
#  top: "accuracy"
#  top: "per_class_accuracy"
#}
